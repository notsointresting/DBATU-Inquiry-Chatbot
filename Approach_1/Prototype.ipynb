{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c835c6",
   "metadata": {},
   "source": [
    " IMPORTING THE LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5380b98c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/DBATU-Inquiry-Chatbot/Approach_1/Prototype.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bubiquitous-engine-7jjv9x74ggx3pp97/workspaces/DBATU-Inquiry-Chatbot/Approach_1/Prototype.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Fix ImportError: cannot import name 'is_sequence' from 'tensorflow.python.util.nest'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bubiquitous-engine-7jjv9x74ggx3pp97/workspaces/DBATU-Inquiry-Chatbot/Approach_1/Prototype.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdisable_eager_execution()\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bubiquitous-engine-7jjv9x74ggx3pp97/workspaces/DBATU-Inquiry-Chatbot/Approach_1/Prototype.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m nest\u001b[39m.\u001b[39mis_sequence \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcontrib\u001b[39m.\u001b[39mframework\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mis_sequence\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bubiquitous-engine-7jjv9x74ggx3pp97/workspaces/DBATU-Inquiry-Chatbot/Approach_1/Prototype.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m nest\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "import time\n",
    "import difflib\n",
    "import numpy\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0d8fc9",
   "metadata": {},
   "source": [
    "PRE-PROCESSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c86acabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'intents.json'\n",
    "\n",
    "with open(file_path) as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    with open('data.pickle','rb') as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except:\n",
    "    words,labels,docs_patt,docs_tag = [],[],[],[]\n",
    "    \n",
    "# TOKENISATION & STEMMING\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            for item in wrds:\n",
    "                words.extend(wrds)\n",
    "                docs_patt.append(wrds)\n",
    "                docs_tag.append(intent['tag'])\n",
    "                if intent['tag'] not in labels:\n",
    "                    labels.append(intent['tag'])\n",
    "    \n",
    "    words = [stemmer.stem(w.lower()) for w in words]\n",
    "    words = sorted(list(set(words)))\n",
    "    labels = sorted(labels)\n",
    "    \n",
    "    training = []\n",
    "    output = []\n",
    "    \n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "# BAG OF WORDS - FEATURE ENGINEERING\n",
    "    \n",
    "    for x,doc in enumerate(docs_patt):\n",
    "        bag = []\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "                \n",
    "            else:\n",
    "                bag.append(0)\n",
    "                \n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_tag[x])] = 1\n",
    "        \n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "        \n",
    "    training = numpy.array(training)\n",
    "    output = numpy.array(output)\n",
    "    \n",
    "    with open('data.pickle','wb') as f:\n",
    "        pickle.dump((words,labels,training,output),f)       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d31f0a",
   "metadata": {},
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bc45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None,len(training[0])])\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,8)\n",
    "net = tflearn.fully_connected(net,len(output[0]),activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dd825",
   "metadata": {},
   "source": [
    "BATCH GRADIENT DESCEND -> BATCH SIZE=8, NO. OF EPOCHES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88426699",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load('model.tflearn')\n",
    "except:\n",
    "    model = tflearn.DNN(net)\n",
    "    history = model.fit(training,output,n_epoch=1000,batch_size=8,show_metric=True)\n",
    "    model.save('model.tflearn')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8a24e",
   "metadata": {},
   "source": [
    "INPUT PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    \n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "    \n",
    "    for se in s_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "    return numpy.array(bag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69485d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_list(s):\n",
    "    a = []\n",
    "    ns = \"\"\n",
    "    s = s + \" \"\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        if s[i] == \" \":\n",
    "            a.append(ns)\n",
    "            ns = \"\"\n",
    "        else:\n",
    "            ns = ns + s[i]\n",
    "            \n",
    "    a = list(set(a))\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ad10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASSS THE FILE IN THIS FUNCTION TO CREATE A DICITIONARY OF UNIQUE VOCABULARY\n",
    "\n",
    "def json_to_dictionary(data):\n",
    "    dictionary = []\n",
    "    fil_dict = []\n",
    "    vocalubary = []\n",
    "    for i in data['intents']:\n",
    "        for pattern in i['patterns']:\n",
    "            vocalubary.append(pattern.lower())\n",
    "            \n",
    "    for i in vocalubary:\n",
    "        dictionary.append(words_to_list(i))\n",
    "        \n",
    "    for i in range(len(dictionary)):\n",
    "        for word in dictionary[i]:\n",
    "            fil_dict.append(word)\n",
    "    return list(set(fil_dict))\n",
    "\n",
    "# THIS FUNCTION CHECKS THE SPELLING IN THE SENTENCE\n",
    "chatbot_vocalubary = json_to_dictionary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ca447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_checker(s):\n",
    "    correct_string = \"\"\n",
    "    for word in s.casefold().split():\n",
    "        if word not in chatbot_vocalubary:\n",
    "            suggestion = difflib.get_close_matches(word,chatbot_vocalubary)\n",
    "            \n",
    "            for x in suggestion:\n",
    "                pass\n",
    "            if len(suggestion) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                correct_string = correct_string + \" \" + str(suggestion[0])\n",
    "                \n",
    "        else:\n",
    "            correct_string = correct_string + \" \" + str(word)\n",
    "            \n",
    "    return correct_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357fd3c",
   "metadata": {},
   "source": [
    "CHAT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"BOT : Hi! I am your personal bot. I am here to answer queries on DBATU\")\n",
    "    while True:\n",
    "        inp = input('YOU : ')\n",
    "        if inp.lower() == 'quit' or inp == None:\n",
    "            break\n",
    "            \n",
    "        inp_x = word_checker(inp)\n",
    "        results = model.predict([bag_of_words(inp_x,words)])[0]\n",
    "        results_index = numpy.argmax(results)\n",
    "        tag = labels[results_index]\n",
    "        \n",
    "        if results[results_index] >= 0.9:\n",
    "            for tg in data['intents']:\n",
    "                if tg['tag'] == tag:\n",
    "                    responses = tg['responses']\n",
    "                    ms = random.choice(responses)\n",
    "                    print('BOT : {}'.format(ms))\n",
    "                    \n",
    "                \n",
    "        else:\n",
    "            print(\"BOT : Sorry, I don't know how to answer that yet\")\n",
    "            \n",
    "            \n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a8896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1035aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc398740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006bcd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
