{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q --upgrade google-generativeai langchain-google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import textwrap\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " genai.GenerativeModel(\n",
       "   model_name='models/gemini-pro',\n",
       "   generation_config={}.\n",
       "   safety_settings={}\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name = \"gemini-pro\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    \"What is Mixture of Experts?\"\n",
    "]\n",
    "\n",
    "response = model.generate_content(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> A Mixture of Experts (MoE) is a powerful machine learning technique used in deep neural networks to address the challenge of modeling complex relationships and patterns in data. It is a type of ensemble method, meaning it combines multiple models or experts to make predictions.\n",
       "> \n",
       "> **Key Concepts:**\n",
       "> \n",
       "> 1. **Experts:** In MoE, each expert is a sub-model or a neural network module that specializes in learning a specific aspect of the input data. These experts can be trained independently, allowing for efficient parallelization during training.\n",
       "> \n",
       "> 2. **Gating Network:** A gating network, also known as a mixture density network, is employed to determine the influence or weight of each expert for each data point. It predicts a probability distribution over the experts, indicating their relevance to the input.\n",
       "> \n",
       "> 3. **Output:** The final output of the MoE model is typically a weighted average of the predictions from each expert, where the weights are determined by the gating network.\n",
       "> \n",
       "> **Advantages:**\n",
       "> \n",
       "> 1. **Enhanced Representation Learning:** MoE allows for more expressive representation learning by capturing the interactions between different experts. This enables the model to better handle complex relationships and patterns in the data.\n",
       "> \n",
       "> 2. **Efficient Parallelization:** The independent training of experts facilitates efficient parallelization during training. This can significantly reduce training time, especially for large datasets and complex models.\n",
       "> \n",
       "> 3. **Interpretability:** MoE models provide a certain level of interpretability by allowing the analysis of the contribution of each expert to the final prediction. This can help in understanding the decision-making process of the model.\n",
       "> \n",
       "> **Applications:**\n",
       "> \n",
       "> 1. **Natural Language Processing (NLP):** MoE has been successfully used in NLP tasks such as machine translation, text classification, and sentiment analysis. By employing experts that specialize in different aspects of language, MoE models can achieve state-of-the-art performance.\n",
       "> \n",
       "> 2. **Computer Vision:** In computer vision, MoE models have demonstrated promising results in tasks like object detection, image classification, and segmentation. The experts can focus on specific visual features, leading to more accurate and robust predictions.\n",
       "> \n",
       "> 3. **Speech Recognition and Generation:** MoE models have been employed in speech recognition and generation systems to improve the accuracy and naturalness of speech synthesis and recognition.\n",
       "> \n",
       "> **Conclusion:**\n",
       "> \n",
       "> Mixture of Experts (MoE) is a powerful machine learning technique that combines multiple experts or sub-models to enhance representation learning and address complex relationships in data. Its advantages include efficient parallelization, interpretability, and applicability to diverse domains such as NLP, computer vision, and speech processing. As research in MoE continues, we can expect further advancements and applications of this technique in various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain to Access Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> A Mixture of Experts (MoE) is a type of ensemble model in machine learning that combines the predictions of multiple individual models, or experts, to make a final prediction. Each expert specializes in a different part of the input space, and the MoE model selects the expert that is most suitable for a given input instance. This allows the MoE model to make more accurate predictions by combining the expertise of multiple models.\n",
       "> \n",
       "> MoE models are often used in tasks where the input data is high-dimensional and complex, such as image recognition, natural language processing, and speech recognition. In these tasks, it is often difficult for a single model to learn all of the relevant information from the input data. By combining the predictions of multiple models, MoE models can achieve better performance than any of the individual models on their own.\n",
       "> \n",
       "> The architecture of a MoE model typically consists of two layers:\n",
       "> \n",
       "> 1. **Expert Layer:** This layer consists of multiple individual models, or experts. Each expert is trained on a different subset of the training data, and they specialize in different parts of the input space.\n",
       "> 2. **Gating Layer:** This layer selects the expert that is most suitable for a given input instance. The gating layer can be implemented using a variety of methods, such as a softmax function or a decision tree.\n",
       "> \n",
       "> Once the gating layer has selected an expert, the output of that expert is used as the final prediction of the MoE model.\n",
       "> \n",
       "> MoE models have several advantages over other ensemble models, such as:\n",
       "> \n",
       "> * **Reduced Overfitting:** By combining the predictions of multiple models, MoE models can help to reduce overfitting to the training data. This is because each expert is trained on a different subset of the data, and they are therefore less likely to learn the same features from the data.\n",
       "> * **Improved Generalization:** MoE models can also help to improve generalization to new data. This is because the experts in a MoE model are trained on different parts of the input space, and they are therefore more likely to be able to make accurate predictions on new data that is different from the training data.\n",
       "> * **Scalability:** MoE models can be easily scaled to large datasets and large numbers of experts. This is because the experts in a MoE model can be trained independently of each other, and the gating layer can be implemented using a variety of efficient algorithms.\n",
       "> \n",
       "> MoE models have been successfully applied to a wide variety of machine learning tasks, including image recognition, natural language processing, and speech recognition. They have also been used in reinforcement learning and generative modeling."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "result = llm.invoke(\"What is Mixture of Experts?\")\n",
    "to_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                             temperature=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0117 13:18:43.960750538   14357 backup_poller.cc:127]                 Run client channel backup poller: UNKNOWN:pollset_work {created_time:\"2024-01-17T13:18:43.96058055+00:00\", children:[UNKNOWN:Bad file descriptor {syscall:\"epoll_wait\", os_error:\"Bad file descriptor\", errno:9, created_time:\"2024-01-17T13:18:43.960529585+00:00\"}]}\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install PyPDF2\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_pdf_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_docs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_dataset.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m, in \u001b[0;36mget_pdf_text\u001b[0;34m(pdf_docs)\u001b[0m\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdf_docs:\n\u001b[0;32m----> 4\u001b[0m     pdf_reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf_reader\u001b[38;5;241m.\u001b[39mpages:\n\u001b[1;32m      6\u001b[0m         text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/PyPDF2/_reader.py:317\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    311\u001b[0m     logger_warning(\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfReader stream/file object is not in binary mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt may not be read correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    315\u001b[0m     )\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(stream)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 't'"
     ]
    }
   ],
   "source": [
    "get_pdf_text(pdf_docs='test_dataset.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
